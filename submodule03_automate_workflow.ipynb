{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e5d6a0-1bf7-4fa8-a981-b8f7da588f76",
   "metadata": {},
   "source": [
    "# Submodule 3: Workflow automation with Nextflow and aquisition of public datasets\n",
    "--------\n",
    "## Overview\n",
    "\n",
    "The primary goal of this submodule is to **generate multiple genome datasets** that will be used in the subsequent submodule on comparative genomics. This will be a short submodule in terms of content, but it is the most computationally intensive submodule.\n",
    "\n",
    "To achieve this, we will **automate the processes outlined in Submodules 1 & 2** using **Nextflow**, a workflow management platform designed to streamline and ensure reproducibility in bioinformatics pipelines. Nextflow allows us to automate the entire workflow, including program version control, ensuring data integrity, and facilitating parallel execution of multiple datasets. This enables us to efficiently run many genome datasets simultaneously, while managing the computational resources available in our environment.\n",
    "\n",
    "After executing the Nextflow workflow on our set of genomes, we will supplement our data with **reference-quality genome sequences from NCBI** in **Submodule 4**.\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "- **Learn Reproducibility in Bioinformatics**:  \n",
    "  Understand the importance of reproducibility in bioinformatics workflows and learn how to implement practices that ensure consistent, reliable results across different systems and environments.\n",
    "\n",
    "- **Automate Genome Data Processing**:  \n",
    "  Learn how to automate and streamline the processes of genome assembly, quality control, and annotation to handle multiple genome datasets efficiently using the workflow management platform **Nextflow**.\n",
    "\n",
    "- **Execute Parallel Processing and Ensure Data Integrity**:  \n",
    "  Gain proficiency in managing and processing large sets of genomic data simultaneously, while also developing the ability to monitor, assess, and maintain data integrity and quality throughout the workflow.\n",
    "\n",
    "- **Prepare and Refine Genome Sequences for Comparative Genomics**:  \n",
    "  Refine and prepare a collection of genome datasets, ensuring they are processed, cleaned, and ready for detailed examination in comparative genomics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df288aa-a092-4803-9b2b-ac53da83b7d2",
   "metadata": {},
   "source": [
    "## The Importance of Reproducibility in Bioinformatics\n",
    "\n",
    "Reproducibility is a cornerstone of scientific research, particularly in bioinformatics, where computational analyses of biological data play a significant role in advancing our understanding of genomics, disease, and evolution. In bioinformatics, ensuring that analyses can be repeated with the same results is critical for validating findings and building trust within the scientific community. This is especially important given the large datasets and complex analyses often involved, where slight variations in workflows, software versions, or data can lead to different outcomes. Reproducible research ensures that experiments can be independently verified, improving the credibility of results and facilitating the development of robust, evidence-based conclusions.\n",
    "\n",
    "To support reproducibility in bioinformatics, many workflows are built using standardized, transparent tools and platforms, such as **Nextflow**, **Snakemake**, and **Galaxy**, which allow scientists to document and automate every step of their analysis. This makes it possible for others to re-run the same pipeline on their own systems, using the same parameters and input data, thus ensuring consistent results.\n",
    "\n",
    "### FAIR Principles\n",
    "\n",
    "The FAIR principles are guidelines designed to enhance the visibility and accessibility of research data. FAIR stands for **Findable, Accessible, Interoperable, and Reusable**. These principles aim to make scientific data easier to find, use, and share, which is especially important in bioinformatics.\n",
    "\n",
    "- **Findable**: Data should be easy to locate through searchable metadata, unique identifiers, and standardized naming conventions.\n",
    "- **Accessible**: Data should be available in formats that are easy to access and retrieve, even if only through proper authentication or permissions.\n",
    "- **Interoperable**: Data and tools should be compatible, allowing for the exchange of information across systems, platforms, and communities.\n",
    "- **Reusable**: Data should be well-documented, with clear descriptions of methods, metadata, and usage licenses, so others can confidently reuse it in future research.\n",
    "\n",
    "### Tools  to Aid in Reproducability in Bioinformatics\n",
    "To ensure reproducibility in bioinformatics workflows, several tools and platforms are available that help automate, document, and track the analysis process. These tools facilitate consistent execution of pipelines, improve collaboration, and ensure that results can be verified and reproduced across different environments and systems.\n",
    "\n",
    "| Tool               | Description | Link |\n",
    "|--------------------|-------------|------|\n",
    "| **Nextflow**       | A workflow management system for running bioinformatics pipelines in a highly scalable, reproducible, and portable manner. | [Nextflow Documentation](https://www.nextflow.io/) |\n",
    "| **RepeatFS**       | A tool designed to automate repetitive computational tasks, similar to Nextflow, for large-scale genomic data analysis. | [RepeatFS GitHub](https://github.com/RepeatFS) |\n",
    "| **Snakemake**      | A popular workflow management system for bioinformatics, known for its simple syntax and scalability. | [Snakemake Documentation](https://snakemake.readthedocs.io/en/stable/) |\n",
    "| **Cromwell**       | A workflow engine designed for scientific workflows, with built-in support for WDL (Workflow Description Language). | [Cromwell GitHub](https://github.com/broadinstitute/cromwell) |\n",
    "| **Galaxy**         | A web-based platform for data-intensive research, offering tools for reproducible data analysis and workflow management. | [Galaxy Project](https://galaxyproject.org/) |\n",
    "| **Airflow**        | An open-source tool for orchestrating complex workflows, with strong scheduling and monitoring features. | [Apache Airflow](https://airflow.apache.org/) |\n",
    "| **Bash / Python**  | Bash and Python scripts can automate tasks, with Bash being simple and flexible for Unix-like systems and Python offering more extensive libraries for bioinformatics tasks. | [Bash Scripting Guide](https://www.gnu.org/software/bash/manual/bash.html), [Python Documentation](https://docs.python.org/3/) |\n",
    "| **Other Languages**| Other programming languages like **R**, **Perl**, and **Ruby** can be used for bioinformatics workflows, depending on the user's needs and preferences. | N/A |\n",
    "| **PipeLine**       | A pipeline management tool that allows for easy tracking and execution of bioinformatics workflows, especially useful in large-scale projects. | [PipeLine GitHub](https://github.com/Pipeline) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62c7ea-5c84-456c-9e96-6a34075f3cab",
   "metadata": {},
   "source": [
    "## **Install required software**\n",
    "\n",
    "The only additional tools required for this submodule is **Nextflow**. All the tools required for the Nextflow workflow have already been installed and described in the previous submodules. To install Nextflow see the official documentation https://www.nextflow.io/docs/latest/install.html. **Nextflow has been installed in the container and does not need to be installed now.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce2ef2-9607-4c73-a5d1-61c813f5741b",
   "metadata": {},
   "source": [
    "## Starting Data\n",
    "As a reminder from Submodule 1, the data used for this module is described in a manuscript comparing phenotypic and whole-genome sequencing-derived AMR profiles ([Painset et al. 2020](https://pubmed.ncbi.nlm.nih.gov/31943013/)). The study includes sequencing read datasets for 528 isolates of Campylobacter spp. (452 C. jejuni and 76 C. coli) from human (494), food (21), and environmental (2) sources.\n",
    "\n",
    "For a robust comparative genomic analysis, it is essential to include a balanced and statistically sufficient sample size for each species. A minimum of 50-100 isolates per species is recommended to capture population-level variability, with larger sample sizes (e.g., 100-200) providing greater statistical power to detect subtle genomic differences.\n",
    "\n",
    "For this tutorial, we will use a small subset of ~10 isolates to ensure analyses run quickly. However, the methods presented here are fully scalable and can be applied to larger datasets like those described in the manuscript. This smaller subset of sequencing data is derived from Table 2. of the manuscript.\n",
    "\n",
    "Lets take a look at the starting dataset. We'll download this data from the NCBI SRA database using the SRA accession column and the same methods we used in Submodule 1.\n",
    "\n",
    "| **Isolate No.** | **SRA Accession** | **Species**  | **Resistance to Erythromycin (Macrolide)** | **Resistance to Ciprofloxacin (Fluoroquinolone)** | **Resistance Determinants (Ciprofloxacin)** | **Resistance to Tetracycline (Tetracycline)** | **Resistance Determinants (Tetracycline)** | **Resistance to Gentamicin (Aminoglycoside)** | **Resistance Determinants (Gentamicin)** | **Resistance to Streptomycin (Aminoglycoside)** | **Resistance Determinants (Streptomycin)** |\n",
    "|------------------|-------------------|--------------|--------------------------------------------|--------------------------------------------------|---------------------------------------------|----------------------------------------------|---------------------------------------------|-----------------------------------------------|-------------------------------------------|------------------------------------------------|---------------------------------------------|\n",
    "| 72               | SRR10067958      | *C. jejuni*  | S                                          | S                                                | —                                           | R                                            | —                                           | S                                             | —                                         | S                                              | —                                           |\n",
    "| 91               | SRR10068079      | *C. jejuni*  | S                                          | S                                                | gyrA_CJ[86:T-I]                             | S                                            | tet(O)                                      | S                                             | —                                         | S                                              | —                                           |\n",
    "| 145              | SRR10068117      | *C. jejuni*  | S                                          | S                                                | —                                           | R                                            | —                                           | S                                             | —                                         | S                                              | —                                           |\n",
    "| 193              | SRR10056681      | *C. jejuni*  | S                                          | S                                                | gyrA_CJ[86:T-I]                             | R                                            | tet(O)_2                                    | S                                             | —                                         | R                                              | —                                           |\n",
    "| 213              | SRR10056829      | *C. jejuni*  | S                                          | S                                                | —                                           | S                                            | tet(O)                                      | S                                             | —                                         | S                                              | ant(6)-Ia, aadE-Cp2                        |\n",
    "| 214              | SRR10056914      | *C. coli*    | S                                          | S                                                | —                                           | S                                            | —                                           | S                                             | —                                         | S                                              | —                                           |\n",
    "| 242              | SRR10056778      | *C. coli*    | S                                          | S                                                | —                                           | S                                            | —                                           | S                                             | —                                         | R                                              | —                                           |\n",
    "| 248              | SRR10056855      | *C. jejuni*  | S                                          | S                                                | 23s_CJ[2074:A-M], gyrA_CJ[86:T-I; 90:D-N]  | R                                            | tet(O)_2                                    | S                                             | —                                         | S                                              | —                                           |\n",
    "| 263              | SRR10056784      | *C. jejuni*  | S                                          | S                                                | gyrA_CJ[86:T-I]                             | R                                            | tet(O)_2                                    | S                                             | —                                         | R                                              | ant(6)-Ia, aadE-Cp2                        |\n",
    "| 276              | SRR10056856      | *C. jejuni*  | S                                          | S                                                | —                                           | S                                            | —                                           | S                                             | —                                         | R                                              | —                                           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833d922-751b-4fb3-b5fb-c9830e1d551d",
   "metadata": {},
   "source": [
    "## Nextflow Overview\n",
    "\n",
    "**Nextflow** is a powerful workflow management platform designed for bioinformatics and data science. It enables the automation of complex workflows, facilitating reproducibility, parallel execution of tasks, and efficient use of computational resources across different environments. Nextflow is especially useful in genomics pipelines where large-scale datasets need to be processed with consistent results.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features of Nextflow:\n",
    "- **Reproducibility**: Nextflow ensures that workflows are reproducible by capturing the environment, dependencies, and exact command used for each execution.\n",
    "- **Parallelization**: It efficiently runs tasks in parallel, utilizing computational resources optimally, which speeds up large-scale data analyses.\n",
    "- **Compatibility**: Nextflow supports multiple computing environments, including local machines, cloud infrastructure, and high-performance computing clusters.\n",
    "- **Version Control**: Integrated support for managing software versions and dependencies, ensuring consistency across different systems and workflows.\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Resources for Nextflow\n",
    "\n",
    "| Resource | Description | Link |\n",
    "|----------|-------------|------|\n",
    "| **Nextflow Official Documentation** | Comprehensive guide on installation, syntax, and core concepts. | [Nextflow Documentation](https://www.nextflow.io/docs/latest/) |\n",
    "| **Nextflow Tutorials** | Step-by-step tutorials for beginners and advanced users. | [Nextflow Tutorials](https://www.nextflow.io/docs/latest/tutorial/) |\n",
    "| **Nextflow YouTube Channel** | Recorded webinars, conference talks, and demos for visual learners. | [Nextflow YouTube Channel](https://www.youtube.com/c/Nextflow) |\n",
    "| **Nextflow Community Forum** | A forum for discussing issues, asking questions, and sharing knowledge. | [Nextflow Forum](https://www.nextflow.io/community/) |\n",
    "| **Nextflow GitHub Repository** | Access to source code, examples, and community contributions. | [Nextflow GitHub](https://github.com/nextflow-io/nextflow) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d336b-aa1b-459b-83f4-ea73a5dcefa7",
   "metadata": {},
   "source": [
    "### Download starting read datasets\n",
    "\n",
    "Below, we will execute code to download sequencing reads from the SR, similar to what we did in Submodule 01 but this time using a script that takes a list of accessions as input.\n",
    "\n",
    "To use this approach with your own data, simply replace the `SRR_list.txt` file with a custom list of SRA accessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ddb3e-3660-4a30-bc97-728bef630557",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "### SKIPPING DOWNLOAD FROM SRA, BUT HERE ARE INSTRUCTIONS\n",
    "read_dir=wgs-nf/raw-reads/\n",
    "# mkdir -p $read_dir\n",
    "\n",
    "# # Create list of accessions from manuscript metadata\n",
    "# cat data/metadata.tsv  | grep SRR | awk '{print $2}' > data/SRR_list.txt\n",
    "# cat data/SRR_list.txt\n",
    "\n",
    "# # run a custom BASH script that retrieves the data from NCBI\n",
    "# scripts/SRA_download.sh data/SRR_list.txt $read_dir\n",
    "\n",
    "\n",
    "### DOWNLOAD FROM S3 bucket, subset data\n",
    "aws s3 cp s3://nh-inbre-genome-sequencing-and-comparative-genomic-analysis/nextflow-reads/ $read_dir --recursive --quiet\n",
    "\n",
    "\n",
    "# list the contents of the starting directory\n",
    "echo \"Directory contents:\"\n",
    "echo \"--------------------\"\n",
    "ls $read_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e6211c-9911-49e3-ae95-b9146282597b",
   "metadata": {},
   "source": [
    "## Run Nextflow\n",
    "\n",
    "Before we dive into our specific workflow, lets start the process. This will run in the background while we read about what is happening behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3f56d-9993-44c6-8598-001350d4d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# move into working directory\n",
    "cd wgs-nf/\n",
    "\n",
    "# run nextflow with the continue option\n",
    "#nextflow run main.nf --continue\n",
    "nextflow run main.nf --continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36441fa-81b3-42ba-9844-3d651e27bfde",
   "metadata": {},
   "source": [
    "## The Nextflow Workflow\n",
    "\n",
    "### Overview\n",
    "\n",
    "Next we will run a bash command that initiates the Nextflow workflow on a directory containing raw FASTQ files. Each of these paired FASTQ files represents the sequencing data genearted from unique isolates. We begin by listing the contents of the directory and then proceed with executing the Nextflow workflow. This workflow automates all the steps from Submodules 1 and 2, ensuring a seamless process. Nextflow intelligently determines which steps can be executed concurrently (e.g., BLAST and BWA read mapping) and which steps require prior completion of others (e.g., running BlobTools after BLAST and related processes finish).\n",
    "\n",
    "First lets take a quick look at the nextflow code format.\n",
    "\n",
    "### Example of a Nextflow Process: Trimming Paired-End Reads with FASTP\n",
    "Below is a code snippet of the contents of wgs-nf/main.nf as an example of the Nextflow language process for runnign a command. In this step of the workflow, we trim paired-end sequencing reads using **FASTP**. The `RUN_FASTP` process takes paired-end reads as input and outputs the trimmed versions of the reads. Here's the Nextflow code to perform this task:\n",
    "\n",
    "```nextflow\n",
    "// Step 2: Trim paired-end reads with FASTP\n",
    "process RUN_FASTP {\n",
    "    input:\n",
    "    tuple val(sampleid), path(fq1), path(fq2)\n",
    "    \n",
    "    output:\n",
    "    tuple val(sampleid), path(\"${sampleid}.trimmed_R1.fastq.gz\"), path(\"${sampleid}.trimmed_R2.fastq.gz\")\n",
    "    \n",
    "    script:\n",
    "    \"\"\"\n",
    "    fastp -i $fq1 -I $fq2 \\\n",
    "        -o \"$sampleid\".trimmed_R1.fastq.gz -O \"$sampleid\".trimmed_R2.fastq.gz \\\n",
    "        --thread ${params.threads}\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca625f9-9575-41ff-9472-80c84f8aaa83",
   "metadata": {},
   "source": [
    "### Nextflow Workflow: Putting it all together\n",
    "\n",
    "A similar snippet of code exists for each step of the workflow, with controlled options and threads for each step. After all the processes are written you can execute the code using the workflow block. Below is the Nextflow code for this workflow, this includes steps for read assessment, quality control, genome assembly, and various downstream analyses.\n",
    "\n",
    "```nextflow\n",
    "workflow {\n",
    "    // Load paired-end FASTQ files\n",
    "    fastq_files = Channel\n",
    "    .fromFilePairs(params.reads, flat: false)\n",
    "    .map { sample_id, files -> tuple(sample_id, files[0], files[1]) }\n",
    "\n",
    "    // Step 0: Count reads\n",
    "    read_info = fastq_files | ASSESS_READS\n",
    "    read_info.view()\n",
    "\n",
    "    // Step 1: Run FASTQC\n",
    "    fastqc_report = fastq_files | RUN_FASTQC\n",
    "\n",
    "    // Step 2: Trim reads with FASTP\n",
    "    trimmed_fastq = fastq_files | RUN_FASTP\n",
    "\n",
    "    // Step 3: Assemble genome with SPADES\n",
    "    genome = trimmed_fastq | RUN_SPADES\n",
    "\n",
    "    // Step 4.1: Run BWA and Samtools\n",
    "    bwa_channel = trimmed_fastq.join(genome)\n",
    "    bam = RUN_BWA(bwa_channel)\n",
    "\n",
    "    // Step 4.2: Run BUSCO\n",
    "    busco_results = genome | RUN_BUSCO\n",
    "\n",
    "    // Step 4.3: Run QUAST\n",
    "    quast_report = genome | RUN_QUAST\n",
    "\n",
    "    // Step 4.4: Run BLAST\n",
    "    blast_results = genome | RUN_BLAST\n",
    "\n",
    "    // Step 5: Run Blobtools\n",
    "    busco_channel = genome.join(bam).join(blast_results)\n",
    "    blob_output = RUN_BLOBTOOLS(busco_channel)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e26c0-fcd5-4cca-a241-a74a63d91512",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>Attention:</b> Before You Proceed: Pause here and wait for the nextflow code to finish running. The brackets around the block of code will switch from '*' to a number when it is completed </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1bee64-9a00-4b3c-8960-2772f5d3cabd",
   "metadata": {},
   "source": [
    "## Nextflow Output Explanation:\n",
    "The above command simulated the Nextflow workflow run using the --continue option. This simply checks to make sure the intended files exist and runs any parts of the workflow that need to run. For the sake of time most outputs were pre-prepared and only the summaries and finalization should have run. The main output is a directy of proteomes and a report file. We also saved select files from processes throughout the workflow (blobtools plots etc.). Lets view these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64917be4-8cb5-49af-954f-f2119d0183bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# view contents of output directory\n",
    "ls wgs-nf/output-dir/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750492d8-007a-4188-9ad7-bd634a96b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# view the results file\n",
    "cat wgs-nf/results_summary.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2e9ef-cf11-447d-84cc-51994451ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# final output directory for the next steps\n",
    "\n",
    "ls wgs-nf/output-dir/proteomes"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
