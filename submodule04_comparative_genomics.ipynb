{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e4d452-3752-43a5-be5a-65ac3cfa4611",
   "metadata": {},
   "source": [
    "# Submodule 4: Comparative genomics analysis\n",
    "--------\n",
    "In this submodule, you will begin with a directory of proteomes from de novo assembled and annotated genomes. A single bacterial genome was analyzed in Submodules 1 & 2 and we automated the process on many genomes in Submodule 3 to procude a total of XX genome sequences. We will add to this dataset with reference genomes publicly available from NCBI. These genome sequences are curated for quality and provide gene accessions with curated functional information. These datasets are crucial for providing context to our new dataset.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/toxo_multi_alignment.png\" width=\"80%\"/>\n",
    "</p>\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "Through this submodule, users will gain experience in comparative genomics, resulting in an understanding of how to use existing genomes a reference points to better understand the context of a novel genome.\n",
    "\n",
    "- **Access Genome Datasets from the NCBI**:<br>\n",
    "  Participants will use command line tools to acces genomes on NCBI for use in comparative genomics analyses.\n",
    "    \n",
    "- **Perform and Visualize Comparative Genomics Analyses**:<br>\n",
    "  Gain proficiency in using comparative genomics tools and visuazing their outputs. Participants will use these outputs to identify patterns across genomes and develop hypotheses about genome relatedness, gene loss or gain events, and gene duplications.\n",
    "\n",
    "- **Create and Understand Phylogeny Trees**:<br>\n",
    "  Use both ortholog groups and average nucleotide identity in genes to create phylogeny trees. Use phylogeny trees to gain an understanding of the see species relatedness and to understand taxonomic groupings.\n",
    "\n",
    "- **Draw Conclusions about Assembled Genome**:<br>\n",
    "  Using the comparisons to fully annotated genomes, participants should be able to identify patterns in host and strain of comparator genomes and draw their own conclusions about the genomes assembled in submodules 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377c6cb-8acc-4c6a-9caa-1bb3e7e75fd7",
   "metadata": {},
   "source": [
    "## **Install required software**\n",
    "\n",
    "A few more tools are required for Submodule 4; OrthoFinder, UpSet plot, and fastANI. As with submodule 1, we will install these tools using __[Conda](https://docs.conda.io/en/latest/)__.\n",
    "\n",
    "Each piece of software, along with links to publications and documentation, will be described in turn. Below is a brief summary of these tools.\n",
    "\n",
    "### List of software\n",
    "| **Tool**       | **Description**                                                                                                                                                           |\n",
    "|:---------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **OrthoFinder**      | Finds orthogroups and orthologs, infers rooted gene trees for all orthogroups and identifies all of the gene duplication events in those gene trees.                         |\n",
    "| **UpSet Plots**      | UpSet plots are a data visualization method for showing set data with more than three intersecting sets.                                                  |\n",
    "| **fastANI**        | Developed for fast alignment-free computation of whole-genome Average Nucleotide Identity (ANI). ANI is defined as mean nucleotide identity of orthologous gene pairs shared between two microbial genomes.                                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e7605-9f1c-4c35-9492-f5b301a3f332",
   "metadata": {},
   "source": [
    "## Starting Data\n",
    "\n",
    "This submodule begins with a directory of genomes in FASTA format and a directory of proteomes in FAA (FASTA amino acid) format. This module is designd to work with data produced from submodule 3, but feel free replace the FAA files within the directory *proteomes* or add additional FAA files as neeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8631f3-4be5-408e-ac17-356ba87f8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls proteomes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c672628-212e-47d3-9ec5-f020d42f9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls genomes/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a6a7a-c3e3-4d12-b64d-d9959f4b2ba8",
   "metadata": {},
   "source": [
    "## Process 1: Downloading Reference Genomes and Proteomes from NCBI\n",
    "We have a directory of `genomes` and `proteomes` we created in submodules 1-3. To provide these context, we can also access thousands of deposited and annotated bacterial genomes and proteomes from NCBI with a few commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a726735-7171-4330-bb60-b2bd58b4a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# download the list of all refseq assemblies\n",
    "if [[ ! -s assembly_summary_refseq.txt ]]\n",
    "then\n",
    "    wget https://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/assembly_summary_refseq.txt -O assembly_summary_refseq.txt --quiet\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19128ed3-63cf-47f3-b9ca-514f82752355",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# we can use grep to search for our target organism\n",
    "grep \"Staphylococcus aureus\" assembly_summary_refseq.txt | head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf86e68-fe72-4dda-bdb3-017aa996f39e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip</b>: Click on one of the blue highlighted links above to be taken to an assembly page on NCBIs server. Notice how the assembly page is laid out just like a directory and the link looks like a path. This is just like how our cloud server works!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c1ab77-d4b6-451c-9c87-17b9f15989ec",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/ncbi_screenshot.png\" width=\"80%\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4089c-05a3-4ac6-b270-cfb985084049",
   "metadata": {},
   "source": [
    "Let's use grep again to search for our organism, but this time we are going to `sort` the results randomly and take the top 10 results. We can then use `cut` to select only the 20th column which contains the link. After, we will loop through the links and download them by adding the file we want from the assembly directory to the end of the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85690d3-f57e-4e0c-8c62-c5abbf74b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "links=$(grep \"Staphylococcus aureus\" assembly_summary_refseq.txt | sort -R | head -n 10 | cut -f 20)\n",
    "\n",
    "for link in $links\n",
    "do\n",
    "    echo Downloading $(echo $link)\n",
    "\n",
    "    # gets file names\n",
    "    genome_file=$(echo $link | awk -F'/' '{print $NF}')_genomic.fna.gz\n",
    "    proteome_file=$(echo $link | awk -F'/' '{print $NF}')_protein.faa.gz\n",
    "\n",
    "    # gets fna download link\n",
    "    fna=$(echo $link)/$(echo $genome_file)\n",
    "    faa=$(echo $link)/$(echo $proteome_file)\n",
    "\n",
    "    # wget downloads the file\n",
    "    # -P specifies a directory prefix\n",
    "    wget -P genomes/ $fna --quiet\n",
    "    wget -P proteomes/ $faa --quiet\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda0745f-75bd-422e-96fd-2b6829b44331",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# lastly, we have to unzip the genome and proteome files\n",
    "gunzip genomes/*.gz\n",
    "gunzip proteomes/*.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615549a3-0c68-4dc4-b6d2-d22aa7f1fb94",
   "metadata": {},
   "source": [
    "## Process 2: Comparing Average Nucleotide Identity using FastANI\n",
    "Program: FastANI - Fast alignment-free computation of whole-genome Average Nucleotide Identity (ANI)\n",
    "Citation : Jain, C., Rodriguez-R, L.M., Phillippy, A.M. et al. *High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries.* Nat Commun 9, 5114 (2018). https://doi.org/10.1038/s41467-018-07641-9\n",
    "Manual: https://github.com/ParBLiSS/FastANI\n",
    "\n",
    "FastANI is developed for fast alignment-free computation of whole-genome Average Nucleotide Identity (ANI). ANI is defined as mean nucleotide identity of orthologous gene pairs shared between two microbial genomes. FastANI supports pairwise comparison of both complete and draft genome assemblies and avoids expensive sequence alignments in most ANI tools. With all our genomes on hand, we can make an initial comparison of ANI to give a preview of potential patterns among our genome set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789175c-07b7-4935-8158-72ff58546271",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "fastANI -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b69a5-7ba4-4275-bc1c-f22d71633f4e",
   "metadata": {},
   "source": [
    "We want to run FastANI with all of our genomes queried against each other. This corresponds to the example in the manual `fastANI --ql [QUERY_LIST] --rl [REFERENCE_LIST] -o [OUTPUT_FILE]`. The query and reference lists are lists of the paths to our genomes. Let's first make these files. With some more bash looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86229f-a25e-481e-b88c-13c61e2b2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# looping through all genome files in our genome directory\n",
    "for genome in genomes/*\n",
    "do\n",
    "    # readlink gets the full path to the genome, tee writes the path to two files at once\n",
    "    readlink -f $genome | tee -a query_list.txt reference_list.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b89b71-87e8-4abe-a214-f099b43a9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "fastANI --ql query_list.txt --rl reference_list.txt -o fastani_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f5ced-f639-443a-8586-645c37f8e290",
   "metadata": {},
   "source": [
    "# HCGS-Comprative-Genomics\n",
    "NCBI download and Orthofinder analysis\n",
    "\n",
    "## Our Starting data\n",
    "\n",
    "```bash\n",
    "ls /home/share/workshop/faa_files/\n",
    "```\n",
    "\n",
    "## What we will be doing\n",
    "\n",
    "We will be using **Orthofinder** for our main comparative genomic analysis. The manual is very detailed, I recommend taking some time to read it. To run the program we will need some genomes to compare.\n",
    "\n",
    "Orhtofinder Manual: https://github.com/davidemms/OrthoFinder\n",
    "\n",
    "The program takes a set of protein sequences for each species and runs pair-wise comarisons to identify orhtologous groups. For each orthogroup a gene tree is calculated and in the end an overall species tree is computed. To get any sort of meaningful phylogenetic tree we need to be sure to include **at least four different genome datasets**. Ideally we would run this program with all of the avaialble sequences on NCBI. As you can imagine, a pairwise comparison with 1,185 Streptomyces genomes will take a lone time (days). We will therfore run it with a reduced set. Next we will determine what genomes we want to download and go over the best ways to retrieve them from NCBI.\n",
    "\n",
    "\n",
    "## Set up working directories\n",
    "```bash\n",
    "cd ~/genomics_tutorial/\n",
    "mkdir genbank_downloads\n",
    "cd genbank_downloads/\n",
    "```\n",
    "\n",
    "## Locate Reference Data on NCBI\n",
    "\n",
    "FAQs about genome download from NCBI: https://www.ncbi.nlm.nih.gov/genome/doc/ftpfaq/#GBorRS\n",
    "\n",
    "Whatever method you use be sure to grab an outgroup, or don't thats your call.\n",
    "\n",
    "### Method 1: Download speicifc genomes\n",
    "\n",
    "We ran a NCBI blast during the genome assembly tutorial. This BLAST should have given you the closest match against the nt database. Chances are it 'hit' well to many genomes. Choose the top hit to a full genome and follow the links to retriev the download link of the genome FAA from the ftp site.\n",
    "\n",
    "Alternatively, you can download the reference genome used as part of the MR study in staphylococcus.\n",
    "\n",
    "Staphylococcus aureus ATCC 29213 is the reference strain.\n",
    "https://www.ncbi.nlm.nih.gov/assembly/GCF_001879295.1\n",
    "\n",
    "FOllow the links to the FTP download.\n",
    "\n",
    "```bash\n",
    "wget \"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/001/879/295/GCF_001879295.1_StAu00v1/GCF_001879295.1_StAu00v1_protein.faa.gz\"\n",
    "```\n",
    "\n",
    "\n",
    "### Method 2: Download all refseq genomes for your genus\n",
    "\n",
    "link to NCBI prokaryote tables: https://www.ncbi.nlm.nih.gov/genome/browse#!/prokaryotes/\n",
    "link to genome reports FTP: ftp://ftp.ncbi.nlm.nih.gov/genomes/GENOME_REPORTS/\n",
    "\n",
    "* Download the genome report file for all all of prokaryotes\n",
    "\n",
    "We will download the file directly to the server, there is no need to download it to your computer. Right lick on the link and copy the link address. This is a big file so we will filter it a bit first before opening it with tabview.\n",
    "\n",
    "This file has a lot of useful information. For now we really care about column 21 which is the downloa link for the genome on the ftp site. Copy that link and paste it into a browser to see the files. We will then download the FAA files to the server.\n",
    "\n",
    "\n",
    "```bash\n",
    "# download the file\n",
    "wget \"ftp://ftp.ncbi.nlm.nih.gov/genomes/GENOME_REPORTS/prokaryotes.txt\"\n",
    "\n",
    "# view it\n",
    "tabview prokaryotes.txt\n",
    "\n",
    "# grep for species in question and view.\n",
    "grep -i \"Staphylococcus\" prokaryotes.txt | grep REPR | tabview -\n",
    "\n",
    "# print the download commands\n",
    "grep \"Staphylococcus\" prokaryotes.txt | grep REPR | awk -F'\\t' '{print \"wget \"$21\"/*protein.faa.gz\"}'\n",
    "\n",
    "# download all the faa files automatically. -P is the number of processes at a time.\n",
    "grep \"Staphylococcus\" prokaryotes.txt | grep REPR | awk -F'\\t' '{print $21\"/*protein.faa.gz\"}' | xargs -P 1 wget -i\n",
    "\n",
    "# or even better, rename the files as you go. (Delete the files created from the previous command before proceeding).\n",
    "grep \"Staphylococcus\" prokaryotes.txt | grep REPR | sed 's/ /_/g' | awk -F'\\t' '{print $1\"_\"$19\".faa.gz\",$21\"/*protein.faa.gz\"}' | xargs -n 2 -P 1 wget -O\n",
    "```\n",
    "\n",
    "\n",
    "Remove the empty files, some of them don't have annotations and it will mess up the next part.\n",
    "\n",
    "```bash\n",
    "zgrep -c '>' *.faa.gz\n",
    "zgrep -c '>' *.faa.gz | awk -F':' '$2 == 0'\n",
    "\n",
    "# automatic deletion with xargs\n",
    "zgrep -c '>' *.faa.gz| awk -F':' '$2 == 0 {print $1}' | xargs rm\n",
    "```\n",
    "\n",
    "Unzip all the files\n",
    "\n",
    "```bash\n",
    "gunzip *.faa.gz\n",
    "```\n",
    "\n",
    "\n",
    "## Set up orthofinder directory\n",
    "\n",
    "```bash\n",
    "# move to analysis folder\n",
    "mkdir ~/genomics_tutorial/orthofinder-analysis\n",
    "cd ~/genomics_tutorial/orthofinder-analysis\n",
    "\n",
    "\n",
    "# create a soft link to the FAA files we just downloaded\n",
    "ln -s ../genbank_downloads/*.faa ./\n",
    "\n",
    "# create a soft link to the FAA fles from our PROKKA analysis\n",
    "ln -s /home/share/workshop/faa_files/*.faa ./\n",
    "```\n",
    "\n",
    "## Count the number of proteins in all the starting files\n",
    "Think about what these numbers tell us right off the bat.\n",
    "\n",
    "```bash\n",
    "grep -c '>' *.faa\n",
    "```\n",
    "\n",
    "## Run Orthofinder2\n",
    "\n",
    "The input to the program is a directory containing a FAA file for each species.\n",
    "\n",
    "```bash\n",
    "# view the manual\n",
    "orthofinder --help\n",
    "# run the program, it will take some time\n",
    "nohup time orthofinder -t 16 -a 16 -S diamond -f ./ &\n",
    "```\n",
    "\n",
    "## Examine the output files\n",
    "\n",
    "I will review some, but not all of the files. The manual goes into extensive detail.\n",
    "\n",
    "```bash\n",
    "cd Results*/\n",
    "ls\n",
    "```\n",
    "\n",
    "### * Orthogroups.csv\n",
    "\n",
    "A **tab** seperated table. Each orthogroup is a raw, each column is a different sample.\n",
    "\n",
    "The table provides all of the data for orthogroups that are in at least two different samples. If a sample has more than one protein for that particular orthogroup than it will have a comma seperated list for the entry. \n",
    "\n",
    "```bash\n",
    "tabview Orthogroups.csv\n",
    "```\n",
    "\n",
    "### * Orthogroups_UnassignedGenes.csv\n",
    "\n",
    "The same style table. Instead this one contains Orthogroups that are not belonging to an orthogroup, they are unique to a single sample. As you scroll down you should notice the proteins belong to different samples.\n",
    "\n",
    "```bash\n",
    "tabview Orthogroups_UnassignedGenes.csv\n",
    "```\n",
    "\n",
    "###  * Orthogroups.GeneCount.csv\n",
    "\n",
    "My favorite 'Orthogroup' Output file. Orthogroups are the rows, columns are gene counts per species. This can be easily parsed to see what orthogroups are specific to waht species. It provides total gene counts for each sample.\n",
    "\n",
    "```bash\n",
    "tabview Orthogroups.GeneCount.csv\n",
    "```\n",
    "\n",
    "* add annotations from a reference sequence\n",
    "\n",
    "~/orthogroups_add_annotations.py <reference_faa> Orthogroups.txt  Orthogroups.GeneCount.csv\n",
    "\n",
    "```bash\n",
    "orthogroups_add_annotations.py ../GCF_000203835.1_ASM20383v1_protein.faa Orthogroups.txt  Orthogroups.GeneCount.csv | tabview -\n",
    "```\n",
    "\n",
    "\n",
    "## Statistics\n",
    "\n",
    "### * Statistics_Overall.csv\n",
    "\n",
    "A file containing the overall statistcis for the analysis. Total number of genes in the dataset etc. \n",
    "\n",
    "```bash\n",
    "tabview Statistics_Overall.csv\n",
    "```\n",
    "\n",
    "### * Statistics_PerSpecies.csv\n",
    "\n",
    "In my opinion this is the most important statistics output file. It provides details for each sample. How many genes were speciifc to that sample. If you want to know a quick statistics of how 'differen't your genome is, this is it.\n",
    "\n",
    "```bash\n",
    "tabview Statistics_PerSpecies.csv\n",
    "```\n",
    "\n",
    "### * WorkingDirectory/\n",
    "\n",
    "All of the work that external programs like BLAST or DIAMOND. 'ls' this directory. It contains all the results for each pairwise comparison.\n",
    "\n",
    "### * Orthologues_DATE/\n",
    "\n",
    "This directory contains a lot of useful data related to the Orthofinder analysis and how they commpute the phylogenetic trees.\n",
    "\n",
    "#### * Recon_Gene_Trees/\n",
    "\n",
    "A directory containing inferred trees for every orthogroup.\n",
    "\n",
    "#### * SpeciesTree_rooted.txt\n",
    "\n",
    "A rooted-species tree. Orthofinder commputes a root for the tree automatically. You can view this in any tree viewing program like FigTree or TreeView (macs). This file is in newick format. Check it out.\n",
    "\n",
    "```bash\n",
    "more Orthologues*/SpeciesTree_rooted.txt\n",
    "```\n",
    "\n",
    "## Export the tree file and view.\n",
    "\n",
    "\n",
    "## Bonus - Figures\n",
    "```\n",
    "orthogroups_add_annotations.py ../GCF_000203835.1_ASM20383v1_protein.faa Orthogroups.txt  Orthogroups.GeneCount.csv\n",
    "\n",
    "orthotools-venn.py Results_*/ PROKKA_*.faa species1.faa species2.faa  venn\n",
    "\n",
    "orthotools-UpSet.R Results_*/Orthogroups.GeneCount.csv\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece61dbc-beaf-4f36-8158-1ed5145a3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the required packages\n",
    "import requests\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import random\n",
    "print(\"done installing required packages\")\n",
    "\n",
    "#install the module quiz_module.py\n",
    "##from quiz_module import run_quiz\n",
    "from quiz_module import run_quiz\n",
    "print(\"done installing quiz_module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0ec3b-0b2e-44f2-9377-9cb514ec1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This randomizes the order of the possible answers.\n",
    "##import_type should be one of two str values: 'json' or 'url'\n",
    "##import_path here defines the json filepath\n",
    "run_quiz(import_type=\"json\", import_path=\"questions/1-1.json\", instant_feedback=False, shuffle_questions=False, shuffle_answers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7644244-797e-4208-8b00-cc743619355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ete2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc756ae-6583-4096-82a5-e90410d9f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phylogenetic tree\n",
    "\n",
    "Phylo\n",
    "ETE toolkit\n",
    "ToyTree\n",
    "\n",
    "https://github.com/etetoolkit/ete\n",
    "\n",
    "http://etetoolkit.org/ipython_notebook/\n",
    " ETE Toolkit - Visualization and analyses using Ipython Notebooks \n",
    "The ETE toolkit - Ipython notebook integration\n",
    "\n",
    "https://toytree.readthedocs.io/en/latest/\n",
    "\n",
    "#South Dokota is doing one\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e7750-0132-418f-b22a-bc6ff0948f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ea516-5a0a-46c9-8ae4-48037398eb74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
