{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a251c4b-9e9c-4ce1-b715-a8f1ea7dc7cd",
   "metadata": {},
   "source": [
    "# Submodule 2: Assessment of genome assembly and genome annotation\n",
    "--------\n",
    "## Overview\n",
    "In this submodule, you will begin with the genome that you assembled in Submodule 1. The primary goal of this submodule is to assess the quality of the assembled genome through the lens of what we call the \"5 Cs\": Contiguity, Completeness, Contamination, Coverage, and Content. By utilizing a combination of bioinformatics tools, participants will evaluate the assembled genome and generate outputs that include visualizations, a cleaned genome sequence and functional annotations. These outputs wil will be used in submodule 4.\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "Through this submodule, users will gain hands-on experience in quality assessment, resulting in a deeper understanding of genomic data integrity and the significance of accurate genome sequences.\n",
    "\n",
    "- **Understand and Apply the 5 Cs of Genome Quality**:  \n",
    "  Understand how to assess the overall quality of a genome sequence by examing Contiguity (QUAST), Completeness (BUSCO), Contamination (BLAST/BlobTools), Coverage (BWA/Samtools), and Content (Prokka gene annotations).\n",
    "\n",
    "- **Understand Core Bioinformatic File Formats and Interpret Visualizations**:  \n",
    "  Gain proficiency in using bioinformatics tools and foster skills in data analysis and interpretation.\n",
    "\n",
    "- **Relate the Central Dogma of Molecular Biology to Genome Annotation**:  \n",
    "  Connect the principles of the central dogma (DNA → RNA → Protein) to the process of genome annotation, understanding how gene annotations contribute to functional genomics and biological interpretations.\n",
    "\n",
    "- **Produce a Clean and Annotated Genome**:  \n",
    "  Participants will refine the genome based on their assessments, ensuring a high-quality, annotated genome that can be used for further analysis or research applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048beb3d-6133-4361-96c3-eb05e9c28135",
   "metadata": {},
   "source": [
    "## **Install required software**\n",
    "\n",
    "Several additional tools are required for Submodule 2; quast, busco, bwa, samtools, blast, blobtools, and prokka.  As with submodule 1, tools are preinstalled into a docker image, but we will demonstrate how to install these tools using __[Conda](https://docs.conda.io/en/latest/)__.\n",
    "\n",
    "Each piece of software, along with links to publications and documentation, will be described in turn. Below is a brief summary of these tools.\n",
    "\n",
    "### List of software\n",
    "| **Tool**       | **Description**                                                                                                                                                           |\n",
    "|:---------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **QUAST**      | Used for evaluating and reporting the quality of genome assemblies by comparing them against reference genomes or generating statistical summaries.                          |\n",
    "| **BUSCO**      | Utilized for assessing genome completeness by searching for conserved single-copy orthologs from specific lineage datasets.                                                 |\n",
    "| **BWA**        | A fast and memory-efficient tool for aligning sequence reads to large reference genomes, commonly used in variant calling pipelines.                                         |\n",
    "| **Samtools**   | Used for manipulating and processing sequence alignments stored in SAM/BAM format. Essential for sorting, indexing, and viewing alignment files.                            |\n",
    "| **BLAST**      | A widely used tool for comparing an input sequence to a database of sequences, identifying regions of local similarity and aiding in functional annotation.                  |\n",
    "| **BlobTools**  | A versatile tool for visualizing and analyzing genome assemblies, helping to identify contamination or misassembled regions by correlating sequence features with taxonomy.   |\n",
    "| **Prokka**     | Used for rapid annotation of prokaryotic genomes, identifying genes, coding sequences, rRNAs, tRNAs, and other genomic features.                                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719c82c-e638-42e4-a816-846fa52c646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Install all tools using mamba (a conda alternative) with specific versions\n",
    "\n",
    "echo \"mamba install --channel bioconda \\\n",
    "    quast=5.2.0 \\\n",
    "    busco=5.4.6 \\\n",
    "    bwa=0.7.18 \\\n",
    "    samtools=1.18 \\\n",
    "    blast=2.15.0 \\\n",
    "    blobtools=1.0.1 \\\n",
    "    prokka=1.14.6 \\\n",
    "    -y > /dev/null 2>&1\"\n",
    "\n",
    "echo \"Installation of quast, busco, bwa, samtools, blast, blobtools, and prokka complete.\"\n",
    "\n",
    "quast.py --version\n",
    "busco --version\n",
    "bakta --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d496898-5b34-480f-8702-e9f2a58139fb",
   "metadata": {},
   "source": [
    "## Starting Data\n",
    "\n",
    "This submodule starts with the **genome FASTA** file, this will be the primary input for all programs. We will define this as the variable *genome* now, and use that for the remainder of the workflow. This enables the starting data to be easily changed if a user wants to run this tutorial with their own data.\n",
    "\n",
    "We will also need to original reads from Submodule 1 for the read mapping step. We will use BWA to calculate sequencing coverage and it requires **paired-end sequencing reads in FASTQ format**. We will define these here as *forward* for the R1 sequencing reads and *reverse* for the R2 sequencing reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93fc2f4-b579-4d18-9e3b-1a4a47026de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# starting genome from submodule 1\n",
    "prev_genome=assembled-genome/genome.fasta\n",
    "\n",
    "# raw reads from submodule 1\n",
    "prev_forward=raw-reads/reads_1.fastq.gz\n",
    "prev_reverse=raw-reads/reads_2.fastq.gz\n",
    "\n",
    "# link to a new location (so we can use custom datasets)\n",
    "mkdir -p submodule02_data/\n",
    "genome=submodule02_data/genome.fasta\n",
    "forward=submodule02_data/reads_1.fastq.gz\n",
    "reverse=submodule02_data/reads_2.fastq.gz\n",
    "\n",
    "# Create symbolic links using absolute paths (this way it doesn't use more space)\n",
    "ln -s \"$(realpath \"$prev_genome\")\" $genome\n",
    "ln -s \"$(realpath \"$prev_reverse\")\" $reverse\n",
    "ln -s \"$(realpath \"$prev_forward\")\" $forward\n",
    "\n",
    "ls submodule02_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c8c9b-bd31-4b61-b2b4-c84822767ca4",
   "metadata": {},
   "source": [
    "## Process 1: **Contiguity** assessment using QUAST\n",
    "- Program: **QUAST (Quality Assessment Tool for Genome Assemblies)**\n",
    "- Citation: *Gurevich, A., Saveliev, V., Vyahhi, N., & Tesler, G. (2013). QUAST: quality assessment tool for genome assemblies. Bioinformatics, 29(8), 1072-1075.*\n",
    "- Manual: https://github.com/ablab/quast\n",
    "\n",
    "QUAST is a tool used to evaluate and compare the quality of genome assemblies by providing metrics such as N50, number of contigs, genome length, and misassemblies. Did you get one contig representing your entire genome? Or did you get thousands of contigs representing a highly fragmented genome?\n",
    "\n",
    "QUAST has many functionalities which we will not explore in this tutorial, I encourage you to explore these, for now we are going to use it in its simplest form. The program parses the genome FASTA file and records statsitics about each contig, the length, GC content etc. This type of information is something you would typically provide in a publication or as a way to assess different assemblers/options you may use. \n",
    "\n",
    "The **input** to the program is the genome assembly **FASTA** and the output are various tables and an html/pdf you can export and view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a5245-9a06-4a98-8a00-cd1e0e3db39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "genome=submodule02_data/genome.fasta\n",
    "echo \"Running QUast on genome FASTA file:\" $genome\n",
    "\n",
    "# run quast on the genome assembly\n",
    "quast.py $genome -o output-quast > logfile_quast.txt 2>&1\n",
    "\n",
    "# display output directory contents\n",
    "echo \"QUAST complete, output directory contents:\"\n",
    "ls -l output-quast/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f04e6-41d1-4d41-a669-8ec9c70bada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# open output file\n",
    "cat output-quast/report.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180ea0b-3942-4246-b982-87577cf5a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "from IPython.display import Image\n",
    "IFrame('output-quast/report.html', width=1000, height=550)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d4173-7de0-4a89-934d-c586d2dfe31d",
   "metadata": {},
   "source": [
    "### Explanation of QUAST outputs\n",
    "We used QUAST to assess the contiguity of the genome assembly, the results describes how well the genome was put back together. These statistics allow us to describe our dataset within a manuscript and us allow us to compare different assembly programs, algorithms, and parameters. As mentioned in Submodule01, a typical bacterial genome consists of a single circular chromosome, so ideally, we would expect to end up with a single contig. Unfortunately, this is rarely the case, for reasons we will discuss below.\n",
    "\n",
    "The QUAST report we displayed above provides some basic statistics about our genome assembly. Focus your attention on the values starting at '# contigs'. As described at the top of the report, these statistics are based on all contigs in the library with length >= 500 bps, a typical cutoff for genome assembly submissions. NCBI accepts submission of contigs >= 250 bps in their genome assembly database.\n",
    "\n",
    "#### Focused Results\n",
    "```\n",
    "# contigs                   30      \n",
    "Largest contig              512,707  \n",
    "Total length                1,693,722 \n",
    "GC (%)                      30.29   \n",
    "N50                         180742  \n",
    "L50                         3       \n",
    "```\n",
    "\n",
    "The *de novo* genome assembly resulted in a **total length of 1,693,722 bp across 30 contigs**. If the species of interest is known, you can compare the total genome length against publically available datasets. \n",
    "\n",
    "The **N50 of the assemly is 180,742 bp** , meaning that half of the total assembly length is contained in contigs that are at least this long. N50 is a widely used metric for assessing contiguity, with higher N50 values indicating better assembly quality. The **L50 is 3**, which complements the N50 by showing the smallest number of contigs needed to cover half the genome length. In this case, **the three longest contigs account for at least half of the assembly**. Metrics like N90 and L90 are similar to N50 and L50 but focus on 90% of the genome length.\n",
    "\n",
    "What qualifies as a \"good\" N50 or other metrics depends on the genome being assembled. Larger, more contiguous genomes, such as those with high N50 and low L50, are generally considered better. However, this also depends on the complexity of the organism and the sequencing approach used.\n",
    "\n",
    "QUAST also provides us with the **GC content (30.29%)**, a metric describing the nucleotide composition of the genome. According to **Chargaff's second rule** (see below), GC content is generally constant within a species but can vary widely between unrelated species. GC content vaires significantly across species and comparing the value can provide clues about evolutionary relationships, ecological adaptations, and functional constraints.\n",
    "\n",
    "\n",
    "## Chargaff's Second Rule\n",
    "\n",
    "Chargaff's **second rule** states that within a double-stranded DNA molecule, the base composition is species-specific but exhibits certain patterns:\n",
    "\n",
    "1. **Base Pair Equality**: The proportion of adenine (A) roughly equals the proportion of thymine (T), and the proportion of guanine (G) roughly equals the proportion of cytosine (C). This rule is foundational to the understanding of complementary base pairing in DNA.\n",
    "   - %A ≈ %T\n",
    "   - %G ≈ %C\n",
    "       \n",
    "2. **Species-Specific GC Content**: While the total GC content (\\(%G + %C\\)) and AT content (\\(%A + %T\\)) can vary widely between species, they are relatively consistent within the genome of a given species. This variation is a hallmark of species identity and evolutionary lineage.\n",
    "\n",
    "### Example\n",
    "A genome with 40% GC content will have 60% AT content, but the exact proportions of G and C will always be equal.\n",
    "\n",
    "---\n",
    "\n",
    "### Significance of Chargaff's Second Rule\n",
    "\n",
    "1. **Foundation for Watson and Crick's Model**: Chargaff's observations were critical for deducing the double-helix structure of DNA, where base pairing (A-T and G-C) ensures the rules hold true.\n",
    "\n",
    "2. **Comparative Genomics**: The species-specific nature of GC content allows researchers to use it as a comparative tool for identifying evolutionary relationships, detecting horizontal gene transfer, or distinguishing between microbial strains.\n",
    "\n",
    "3. **Genome Assembly Quality**: Deviations from expected GC content in an assembly may indicate errors, contamination, or sequencing biases, making it a valuable metric in genome analysis tools like QUAST.\n",
    "\n",
    "---\n",
    "\n",
    "In essence, Chargaff's second rule highlights the balance and specificity in DNA's molecular composition, emphasizing both its biochemical properties and its role in evolution and species differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c0697-bf4e-4da1-9a02-ba0a2d591833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Save select Quast Results into log file\n",
    "log_file=\"genome-assessment-log.txt\"\n",
    "\n",
    "echo \"Saving Select Quast Results in log file\"\n",
    "echo \"Quast results:\" > $log_file\n",
    "grep -A 4 \"# contigs\" output-quast/report.txt | tail -n 5 >> $log_file\n",
    "echo \"----------------------------------\" >> $log_file\n",
    "\n",
    "cat $log_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d4b87-b3d8-4b91-acd5-2ee5a7c324aa",
   "metadata": {},
   "source": [
    "## Process 2: **Completeness** assessment using BUSCO\n",
    "\n",
    "- Program: **BUSCO - Benchmarking Universal Single-Copy Orthologs**\n",
    "- Citation: *Seppey, M., Manni, M., & Zdobnov, E. M. (2019). BUSCO: assessing genome assembly and annotation completeness. Gene prediction: methods and protocols, 227-245.*  \n",
    "- Manual: https://busco.ezlab.org/\n",
    "\n",
    "BUSCO is a program utilized to assess the completeness of a genome assembly in terms of the number of found and universal genes. This program makes use of the OrthoDB set of single-copy orthologous that are found in at least 90% of all the organisms in question. There are different data sets for various taxonomic groups (Eukaryotes, Metazoa, Bacteria, Gammaproteobacteria, etc. etc.). The idea is that a newly sequenced genome *should* contain most of these highly conserved genes. If your genome doesn't contain a large portion of these single-copy orthologs it may indicate that your genome is not complete.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/busco_sampling.png\" width=\"40%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "The input to the program is your genome assembly (contigs) as well as a selection of which database to use. The output is a directory with a short summary of the results, a full table with coordinates for each orthologous gene is located in your assembly, and a directory with the nucleotide and amino acid sequences of all the identified sequences.\n",
    "\n",
    "We will focus on the main summary output as a way to provide a simple QC assessment of our assembly, the outputs provided by BUSCO however have many uses, such as phylogenomics and gene prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ac192-7110-4b92-81f6-1ef79a029784",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# View available sets\n",
    "busco --list-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfe6ed-5542-456f-9abf-9c081ef5eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# starting data\n",
    "genome=submodule02_data/genome.fasta\n",
    "\n",
    "# lineage to search against\n",
    "lineage=bacteria\n",
    "\n",
    "# run BUSCO\n",
    "busco -i $genome -m genome -o output-busco -l $lineage --cpu 24 -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2dd37b-99b4-4e8e-b08c-43c99e9b809e",
   "metadata": {},
   "source": [
    "### Explanation of BUSCO output\n",
    "The output displayed above provides a summary of the BUSCO completeness analysis. See the output file 'short_summary_busco_output.txt' for the detaile report. This is a file which summarizes the main findings, how many of the expected genes did we find? This summary breaks the report into four main categories: **complete single-copy genes, complete duplicated genes, fragmented genes, and missing genes**. \n",
    "\n",
    "We are hopeful that the majority of our genes will be found as 'complete single-copy'. Duplicated genes could indicate that that particular gene underwent a gene duplication event or that we had a miss assembly and essentially have two copies of a region of our genome. Fragmented genes are an artifact of the fact that our genome did not assemble perfectly. Some of our genome is fragmented into multiple contigs, and with that some of our genes are going to be fragmented as well. This is why it is important to inspect the N50 of the genome with QUAST. We want the majority of our contigs to be at least as big as a gene, if it's not than we will have many fragmented genes as a result.\n",
    "\n",
    "### Other BUSCO results\n",
    "\n",
    "Next we will view the 'full_table_busco_output.tsv' file. This is a file which shows the coordinates for all the associated single copy genes in our genome. It also provides information about the status of that ortholog (missing, complete, fragmented). This tsv file can be exported and viewed in excel.\n",
    "\n",
    "The final files we will examine are in a directory called 'single_copy_busco_sequences/'. This houses all the amino acid and protein sequences. This is a rich source for comparative genomics and other sorts of analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ef695-b48a-4f92-9248-4b929599e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# examine the table (first ten lines only)\n",
    "echo \"Header:\"\n",
    "grep '# Busco id' output-busco/run_bacteria_odb10/full_table.tsv\n",
    "echo '#############################################'\n",
    "\n",
    "# see the categories of genes\n",
    "echo \"Fragmented genes:\"\n",
    "awk -F'\\t' '$2 == \"Fragmented\"' output-busco/run_bacteria_odb10/full_table.tsv\n",
    "\n",
    "echo '#############################################'\n",
    "echo \"Missing genes:\"\n",
    "awk -F'\\t' '$2 == \"Missing\"' output-busco/run_bacteria_odb10/full_table.tsv\n",
    "\n",
    "echo '#############################################'\n",
    "echo \"Duplicate genes:\"\n",
    "awk -F'\\t' '$2 == \"Duplicate\"' output-busco/run_bacteria_odb10/full_table.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54755f50-3f10-439a-95d3-1e214df4a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Save BUSCO Results\n",
    "log_file=\"genome-assessment-log.txt\"\n",
    "\n",
    "echo \"BUSCO results:\" >> $log_file\n",
    "grep -A 4 'Complete and single-copy BUSCOs' output-busco/short_summary.specific.bacteria_odb10.output-busco.txt \\\n",
    "    | awk -F'\\t' '{print $3\"\\t\"$2}' >> $log_file\n",
    "echo \"----------------------------------\" >> $log_file\n",
    "\n",
    "cat $log_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b999c3-d1c8-409b-a590-6a533947d91f",
   "metadata": {},
   "source": [
    "## Process 3: **Coverage** assessment using BWA\n",
    "\n",
    "- Program: **BWA** and **Samtools**\n",
    "- Citations: *Li, H., & Durbin, R. (2009). Fast and accurate short read alignment with Burrows-Wheeler transform. Bioinformatics, 25(14), 1754–1760. https://doi.org/10.1093/bioinformatics/btp324*, *Li, H., et al. (2009). The Sequence Alignment/Map format and SAMtools. Bioinformatics, 25(16), 2078–2079. https://doi.org/10.1093/bioinformatics/btp352*\n",
    "- BWA manual: https://bio-bwa.sourceforge.net/bwa.shtml\n",
    "- SAMtools manual: http://www.htslib.org/doc/samtools-1.2.html\n",
    "- SAM format specifications: https://samtools.github.io/hts-specs/SAMv1.pdf\n",
    "\n",
    "Read Mapping refers to the process of aligning short reads to a reference sequence. This reference can be a complete genome, a transcriptome, or in our case de novo assembly. Read mapping is fundamental to many commonly used pipelines like differential expression or SNP analysis. We will be using it to calculate the average coverage of each of our contigs and to calculate the overall coverage of our genome (a requirement for genbank submission).The main output of read mapping is a **Sequence Alignment Map format (SAM)**. The file provides information about where our sequencing reads match to our assembly and information about how it maps. There are hundreds of programs that use SAM files as a primary input. A BAM file is the binary version of a SAM, and can be converted very easily using samtools.\n",
    "\n",
    "Many programs perform read mapping. The recommended program depends on what you are trying to do. My favorite is 'BWA mem' which balances performance and accuracy well. The input to the program is a referece assembly and reads to map (forward and reverse). The output is a SAM file. By default BWA writes the SAM file to standard output, I therefore save it directly to a file. There are lots of options, please see the manual to understand what I am using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7007c-b87e-4334-8de6-738c4182c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#genome and reads\n",
    "genome=submodule02_data/genome.fasta\n",
    "forward=submodule02_data/reads_1.fastq.gz\n",
    "reverse=submodule02_data/reads_2.fastq.gz\n",
    "\n",
    "\n",
    "# Step 1: Index your reference genome. This is a requirement before read mapping.\n",
    "bwa index $genome\n",
    "# Step 2: Map the reads and construct a SAM file.\n",
    "bwa mem -t 24 $genome $forward $reverse > raw_mapped.sam\n",
    "# view the file with less, note that to see the data you have to scroll down past all the headers (@SQ).\n",
    "# head -n 200 raw_mapped.sam | less -S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757d9d4-53e5-43a9-b76c-a91b2b19e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Remove sequencing reads that did not match to the assembly and convert the SAM to a BAM.\n",
    "samtools view -@ 24 -Sb  raw_mapped.sam  | samtools sort -@ 24 - -o sorted_mapped.bam\n",
    "\n",
    "# Examine how many reads mapped with samtools\n",
    "samtools flagstat sorted_mapped.bam\n",
    "# Calculate per base coverage with bedtools\n",
    "\n",
    "# index the new bam file\n",
    "samtools index sorted_mapped.bam\n",
    "\n",
    "#bedtools genomecov -ibam sorted_mapped.bam > coverage.out\n",
    "# Calculate per contig coverage with gen_input_table.py\n",
    "#gen_input_table.py  --isbedfiles $fasta coverage.out >  coverage_table.tsv\n",
    "# This outputs a simple file with two columns, the contig header and the average coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd84a5-3d7a-4f1b-b824-e0a1332ed623",
   "metadata": {},
   "source": [
    "## Process 4: Taxonomic assignment using BLAST and blobtools\n",
    "\n",
    "\n",
    "manual: https://www.ncbi.nlm.nih.gov/books/NBK279690/\n",
    "\n",
    "Using the command line BLAST works essentially the same as NCBI BLAST except we have more control. We can specify more options like output formats and also use our own local databases. It is also a lot more useful for pipelines and workflows since it can be automated, you don't need to open a web page and fill out any forms.\n",
    "\n",
    "As a quick example for how BLAST works we will use the same 16S_sequence and BLAST it against our genome assembly. Before we begin we will make a database out of our contig assembly. This is done to construct a set of files that BLAST can use to speed up its sequence lookup. In the end it means we have to wait less time for our results.\n",
    "\n",
    "#### Make a BLAST db from your contig files\n",
    "\n",
    "The only required input is a FASTA file (our contigs), the database type (nucl or prot), and an output name for the new database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01f350-d0be-489d-b1b2-0b4d179a351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "genome=submodule02_data/genome.fasta\n",
    "\n",
    "ref_genomes=wgs-nf/databases/blast_db/reference-genome.fasta\n",
    "\n",
    "makeblastdb -in $ref_genomes -dbtype nucl -out wgs-nf/databases/blast_db/blast_db\n",
    "\n",
    "ls wgs-nf/databases/blast_db/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696979b8-dd31-42a0-ac7f-92513b6c909c",
   "metadata": {},
   "source": [
    "### BLAST genome assembly against the nt database\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/nucleutide-blast-cover.png\" width=\"30%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "We store a local copy of the complete nucleotide database on our server. We will be using this to provide a rough taxonomy to every sequence in our assembly and to ultimately identify non-target contaminates (like human and other bacteria) and to confirm our species identification from the 16S BLAST. Later we will be using the output file as in input to blobtools and to visualize this information. blobtools requires a specifically formatted BLAST file, I therefore provide a script that will run the BLAST to the programs specification. We will simply provide the script with our contigs file and it will complete the task. This is a simple script that is not much different than the example we ran above. It will automatically format a meaningfull output name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77df83-5089-4a97-bdb1-0117e686ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "genome=submodule02_data/genome.fasta\n",
    "database=wgs-nf/databases/blast_db/blast_db\n",
    "\n",
    "blastn \\\n",
    "    -task megablast \\\n",
    "    -query $genome \\\n",
    "    -db $database\\\n",
    "    -outfmt '6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore' \\\n",
    "    -culling_limit 5 \\\n",
    "    -max_target_seqs 10 \\\n",
    "    -num_threads 24 \\\n",
    "    -evalue 1e-5 \\\n",
    "    -out genome.vs.blastdb.cul5.maxt10.1e5.megablast.out > /dev/null 2>&1\n",
    "\n",
    "# view the results\n",
    "echo -e \"qseqid\\t\\t\\t\\t\\tsseqid\\t\\tpident\\tlength\\tmismatch gapopen qstart qend\\tsstart\\tsend\\tevalue\\tbitscore\"\n",
    "head genome.vs.blastdb.cul5.maxt10.1e5.megablast.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b74686-e191-49df-a773-4df1fe8e5da2",
   "metadata": {},
   "source": [
    "## Combine datasets into a blobtools database\n",
    "\n",
    "Program: **BlobTools**\n",
    "Citation: *Laetsch, D. R., & Blaxter, M. L. (2017). BlobTools: Interrogation of genome assemblies. F1000Research, 6, 1287*  \n",
    "Manual: https://blobtools.readme.io/docs  \n",
    "\n",
    "Blobtools is a tool to visualize our genome assembly. It is also useful for filtering read and assembly data sets. There are three main inputs to the program: 1.) Genome assembly **FASTA** file (the one we used for BLAST and BWA), 2.) a 'hits' file generated from **BLAST**, 3.) A SAM or **BAM** file. The main output of the program are blobplots which plot the GC, coverage, taxonomy, and contigs lengths on a single graph.  \n",
    "\n",
    "The first step (blobtools create) in this short pipeline takes all of our input files and creates a lookup table that is used for plotting and constructing tables. This step does the brunt of the working, parsing the BLAST file to assign taxonomy to each of our sequences, and parsing the SAM file to calculate coverage information.  \n",
    "\n",
    "After that is complete we will use 'blobtools view' to output all the data into a human readable table. Finally we will use 'blobtools plot' to construct the blobplot visuals.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf148b-0fd4-462b-93a4-ba78f546947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# BLAST results from previous step\n",
    "blast_results=genome.vs.blastdb.cul5.maxt10.1e5.megablast.out\n",
    "\n",
    "# lookup table that provides taxonomic IDs for BLAST DB accessions. This enables conversion of accessions to full taoxnomic ranks (Kingdom, phylum etc.)\n",
    "taxid_lookup=wgs-nf/databases/blast_db/accessions_to_taxids.txt\n",
    "\n",
    "cat $taxid_lookup\n",
    "\n",
    "# Add taxids to BLAST results\n",
    "# blobtools taxify --help\n",
    "blobtools taxify \\\n",
    "    -f $blast_results \\\n",
    "    -m $taxid_lookup \\\n",
    "    -s 0 \\\n",
    "    -t 1\n",
    "\n",
    "# -s is the column of sequenceID of subject in taxID mapping file\n",
    "# -t is the column of TaxID of sequenceID in taxID mapping file\n",
    "head genome.vs.blastdb.cul5.maxt10.1e5.megablast.taxified.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5cfb06-247c-41a9-9b97-7ca4f7c1d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# input data\n",
    "genome=assembled-genome/contigs.fasta\n",
    "bam=sorted_mapped.bam\n",
    "blast_taxified=genome.vs.blastdb.cul5.maxt10.1e5.megablast.taxified.out\n",
    "\n",
    "# taxonomy database\n",
    "taxdb=wgs-nf/databases/blast_db/nodesDB.txt\n",
    "\n",
    "# Create lookup table\n",
    "blobtools create -i $genome -b $bam -t $blast_taxified -o blob_out --db $taxdb\n",
    "\n",
    "# Create output table\n",
    "blobtools view -i blob_out.blobDB.json -r all -o blob_taxonomy\n",
    "\n",
    "# # view the table, I remove headers with grep -v and view with tabview\n",
    "# grep -v '##' blob_taxonomy.blob_out.blobDB.table.txt\n",
    "\n",
    "# Plot the data\n",
    "blobtools plot -i blob_out.blobDB.json -r genus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd578fc1-6777-4d18-af07-9763c8b40627",
   "metadata": {},
   "source": [
    "## Filter non-target sequences from *de novo* assembly\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/example_blobplot.png\" width=\"50%\"/>\n",
    "</p>\n",
    "\n",
    "The x-axis on these plots is GC content, the y-axis is the coverage (log transformed). The size of the 'blobs' are the length of the contigs. Colors represent taxonomic assignment (the -r option lets you choose which rank to view). The concept of these plots and ultimately for assembly filtering is that each organism has a unique GC content. For example Streptomyces has an average GC content of about 0.72 while other bacteria can go as low as 0.2. In addition, contamination is most likely has much lower coverage compared to the rest of your assembly. Combine that with the taxonomic assignments and you have multiple lines of evidence to identify your non-target contigs. In the plot above you can fairly easily see what contigs we plan to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d2f08-d2b1-4dc3-8649-8eb1ac77765f",
   "metadata": {},
   "source": [
    "## Genome annotation using Bakta\n",
    "\n",
    "- Program: **Bakta** - Rapid & standardized annotation of bacterial genomes, MAGs & plasmids\n",
    "- Citation: *Schwengers, O., Jelonek, L., Dieckmann, M. A., Beyvers, S., Blom, J., & Goesmann, A. (2021). Bakta: rapid and standardized annotation of bacterial genomes via alignment-free sequence identification. Microbial genomics, 7(11), 000685.*  \n",
    "- Manual: https://github.com/oschwengers/bakta\n",
    "- Annotation GFF3 file format: https://useast.ensembl.org/info/website/upload/gff3.html\n",
    "\n",
    "\n",
    "Bakta is a  tool for fast, taxon-independent, annotation of bacterial genomes. Annotation results are exported in **GFF3** and International Nucleotide Sequence Database Collaboration (INSDC)-compliant flat files that can be submitted with your genome to Genbank. Bakta is an alternative tool to the computationally demanding NCBI PGAP and highly customizable Prokka. We use it here for both its lightweight design (i.e. easy installation) and speed (~5 mins).\n",
    "\n",
    "Bakta annotates ncRNA cis-regulatory regions, oriC/oriV/oriT and assembly gaps as well as standard feature types: tRNA, tmRNA, rRNA, ncRNA genes, CRISPR, CDS and pseudogenes. Just like its inspiration (Prokka), bakta is a workflow that relies on other, more specific, annotation tools. We will focus the lesson on annotation to tRNAs, rRNAs, and protein-coding genes (PCGs). Here is a full list of the tools used by Brakta. \n",
    "\n",
    "- tRNAscan-SE (2.0.8) https://doi.org/10.1101/614032 http://lowelab.ucsc.edu/tRNAscan-SE\n",
    "- Aragorn (1.2.38) http://dx.doi.org/10.1093/nar/gkh152 http://130.235.244.92/ARAGORN\n",
    "- INFERNAL (1.1.4) https://dx.doi.org/10.1093%2Fbioinformatics%2Fbtt509 http://eddylab.org/infernal\n",
    "- PILER-CR (1.06) https://doi.org/10.1186/1471-2105-8-18 http://www.drive5.com/pilercr\n",
    "- Pyrodigal (2.1.0) https://doi.org/10.21105/joss.04296 https://github.com/althonos/pyrodigal\n",
    "- PyHMMER (0.10.0) https://doi.org/10.21105/joss.04296 https://github.com/althonos/pyhmmer\n",
    "- Diamond (2.0.14) https://doi.org/10.1038/nmeth.3176 https://github.com/bbuchfink/diamond\n",
    "- Blast+ (2.12.0) https://www.ncbi.nlm.nih.gov/pubmed/2231712 https://blast.ncbi.nlm.nih.gov\n",
    "- AMRFinderPlus (3.10.23) https://github.com/ncbi/amr\n",
    "- DeepSig (1.2.5) https://doi.org/10.1093/bioinformatics/btx818\n",
    "\n",
    "The program is simple to run, but does a lot. After you start the analysis in the next block of code, I suggest watching the following video about genome annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e955c-1306-49b8-97bf-abe56bd9755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Copy the data from an AWS S3 bucket.\n",
    "\n",
    "# output location\n",
    "mkdir -p databases\n",
    "outdir=wgs-nf/databases/bakta_db/\n",
    "\n",
    "# copy from aws S3 bucket\n",
    "aws s3 cp s3://nh-inbre-genome-sequencing-and-comparative-genomic-analysis/databases/bakta-light/ $outdir --recursive --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5240d4-28f6-4481-9727-f58c8b910b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "genome=submodule02_data/genome.fasta\n",
    "database=wgs-nf/databases/bakta_db/\n",
    "\n",
    "## setup bakta database (not required)\n",
    "# wget https://zenodo.org/record/10522951/files/db-light.tar.gz\n",
    "# tar -xzf db-light.tar.gz\n",
    "# rm db-light.tar.gz\n",
    "# mv X wgs-nf/databases/\n",
    "\n",
    "# Run bakta with default options.\n",
    "#bakta --help\n",
    "bakta $genome -o output-bakta/ --db $database --threads 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ec592-0435-4037-b2a1-5a262d89d58b",
   "metadata": {},
   "source": [
    "## Visualize Dataset with Circos\n",
    "\n",
    "Program: **Circos** - pyCirclize is a circular visualization python package implemented based on matplotlib. This package is developed for the purpose of easily and beautifully plotting circular figure such as Circos Plot and Chord Diagram in Python.\n",
    "Manual: https://github.com/moshi4/pyCirclize\n",
    "\n",
    "We can use the Circos class in the pycirclize module to visualize our circular bacterial genome. Using some python code, we can visualize the genome contiguity, coverage, and content in one plot. This code uses the GFF3 and GBFF files from BAKTA to add annotations to the contig assembly. Using the per base coverage, we can see the coverage across contigs and look for any abnormally covered regions.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/example_genome.png\" width=\"40%\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ddf8c1-92ae-4ada-a531-2f31aee7b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# get per base coverage\n",
    "bedtools genomecov -ibam sorted_mapped.bam -d > per_base_coverage.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c176e-b782-4ef2-b84e-621654a1547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# We can call the script with the --help flag to learn how to run the program\n",
    "scripts/circos.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c59e0-811b-4fb8-8d83-60f4b3b040e7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip</b>: Most programs will have a built in help menu. Call the program with the flag <code>--help</code> or <code>-h</code> to learn how to run unfamiliar programs.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e48c8e-1fe7-4821-9a31-8fd5a7878624",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "scripts/circos.py --species \"Enter your species here\" --gff output-bakta/contigs.gff3 --gbk output-bakta/contigs.gbff --bed per_base_coverage.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a8727-50c6-4973-8bae-71292c54bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amrfinder_update --force_update --database /home/sagemaker-user/Genome-Sequencing-and-Comparative-Genomic-Analysis/databases/bakta_db/amrfinderplus-db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf33493-e354-4f73-a344-afb60d4cdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='circos_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0799b3-2ea3-428e-980d-414ca4fe8b33",
   "metadata": {},
   "source": [
    "## Conclusion and wrap up\n",
    "\n",
    "End of submodule 2.  After learning about the general methods of assessing a genome assembly we ran the tools and identifies potential problems with our data.\n",
    "\n",
    "Submodule 4 will begin with a directory of proteomes. One of the final steps of our workflow was runnign bakta to annotate our genome. One of the main outputs is the FAA proteome.\n",
    "\n",
    "Be sure to shut down your instance. We will run one more bit of code to copy our genome file for use in submodule 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
