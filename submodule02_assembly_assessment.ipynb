{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a251c4b-9e9c-4ce1-b715-a8f1ea7dc7cd",
   "metadata": {},
   "source": [
    "# Submodule 2: Assessment of genome assembly and genome annotation\n",
    "\n",
    "In this submodule, you will begin with the genome that you assembled in Submodule 1. The primary goal is to assess the quality of the assembled genome through the lens of what we call the \"5 Cs\": Contiguity, Completeness, Contamination, Coverage, and Content. By utilizing a combination of bioinformatics tools, participants will evaluate the assembled genome and generate outputs that include visualizations, a cleaned genome sequence and functionalannotations. These outputs wil will be used in submodule 4.\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "Through this submodule, users will gain hands-on experience in quality assessment, resulting in a deeper understanding of genomic data integrity and the significance of accurate genome sequences.\n",
    "\n",
    "- **Understand and Apply the 5 Cs of Genome Quality**:  \n",
    "  Understand how to assess the overall quality of a genome sequence by examing Contiguity (QUAST), Completeness (BUSCO), Contamination (BLAST/BlobTools), Coverage (BWA/Samtools), and Content (Prokka gene annotations).\n",
    "\n",
    "- **Generate and Interpret Visualizations**:  \n",
    "  Gain proficiency in using bioinformatics tools and foster skills in data analysis and interpretation.\n",
    "\n",
    "- **Relate the Central Dogma of Molecular Biology to Genome Annotation**:  \n",
    "  Connect the principles of the central dogma (DNA → RNA → Protein) to the process of genome annotation, understanding how gene annotations contribute to functional genomics and biological interpretations.\n",
    "\n",
    "- **Produce a Clean and Annotated Genome**:  \n",
    "  Participants will refine the genome based on their assessments, ensuring a high-quality, annotated genome that can be used for further analysis or research applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048beb3d-6133-4361-96c3-eb05e9c28135",
   "metadata": {},
   "source": [
    "## **Install required software**\n",
    "\n",
    "Several additional tools are required for Submodule 2; quast, busco, bwa, samtools, blast, blobtools, and prokka.  As with submodule 1, we will install these tools using __[Conda](https://docs.conda.io/en/latest/)__.\n",
    "\n",
    "Each piece of software, along with links to publications and documentation, will be described in turn. Below is a brief summary of these tools.\n",
    "\n",
    "### List of software\n",
    "| **Tool**       | **Description**                                                                                                                                                           |\n",
    "|:---------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **QUAST**      | Used for evaluating and reporting the quality of genome assemblies by comparing them against reference genomes or generating statistical summaries.                          |\n",
    "| **BUSCO**      | Utilized for assessing genome completeness by searching for conserved single-copy orthologs from specific lineage datasets.                                                 |\n",
    "| **BWA**        | A fast and memory-efficient tool for aligning sequence reads to large reference genomes, commonly used in variant calling pipelines.                                         |\n",
    "| **Samtools**   | Used for manipulating and processing sequence alignments stored in SAM/BAM format. Essential for sorting, indexing, and viewing alignment files.                            |\n",
    "| **BLAST**      | A widely used tool for comparing an input sequence to a database of sequences, identifying regions of local similarity and aiding in functional annotation.                  |\n",
    "| **BlobTools**  | A versatile tool for visualizing and analyzing genome assemblies, helping to identify contamination or misassembled regions by correlating sequence features with taxonomy.   |\n",
    "| **Prokka**     | Used for rapid annotation of prokaryotic genomes, identifying genes, coding sequences, rRNAs, tRNAs, and other genomic features.                                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719c82c-e638-42e4-a816-846fa52c646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Install all tools using mamba (a conda alternative) with specific versions\n",
    "\n",
    "mamba install --channel bioconda \\\n",
    "    quast=5.2.0 \\\n",
    "    busco=5.4.6 \\\n",
    "    bwa=0.7.18 \\\n",
    "    samtools=1.18 \\\n",
    "    blast=2.15.0 \\\n",
    "    blobtools=1.0.1 \\\n",
    "    prokka=1.14.6 \\\n",
    "    -y > /dev/null 2>&1\n",
    "\n",
    "echo \"Installation of quast, busco, bwa, samtools, blast, blobtools, and prokka complete.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d496898-5b34-480f-8702-e9f2a58139fb",
   "metadata": {},
   "source": [
    "## Starting Data\n",
    "\n",
    "This submodule starts with the **genome FASTA** file, this will be the primary input for all programs. We will define this as the variable *genome* now, and use that for the remainder of the workflow. This enables the starting data to be easily changed if a user wants to run this tutorial with their own data.\n",
    "\n",
    "Read mapping with BWA to calculate sequencing coverage requires **paired-end sequencing reads in FASTQ format**. These are the reads used in Submodule 1 to assemble the genome. We will define these here as *forward* for the R1 sequencing reads and *reverse* for the R2 sequencing reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93fc2f4-b579-4d18-9e3b-1a4a47026de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# starting genome from submodule 1\n",
    "genome=assembled-genome/contigs.fasta\n",
    "\n",
    "# raw reads from submodule 1\n",
    "forward=raw-reads/SRR10056829_1.fastq.gz\n",
    "reverse=raw-reads/SRR10056829_2.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c8c9b-bd31-4b61-b2b4-c84822767ca4",
   "metadata": {},
   "source": [
    "## Process 1: **Contiguity** assessment using QUAST\n",
    "- Program: **QUAST (Quality Assessment Tool for Genome Assemblies)**\n",
    "- Citation: *Gurevich, A., Saveliev, V., Vyahhi, N., & Tesler, G. (2013). QUAST: quality assessment tool for genome assemblies. Bioinformatics, 29(8), 1072-1075.*\n",
    "- Manual: https://github.com/ablab/quast\n",
    "\n",
    "QUAST is a tool used to evaluate and compare the quality of genome assemblies by providing metrics such as N50, number of contigs, genome length, and misassemblies. Did you get one contig representing your entire genome? Or did you get thousands of contigs representing a highly fragmented genome?\n",
    "\n",
    "QUAST has many functionalities which we will not explore in this tutorial, I encourage you to explore these, for now we are going to use it in its simplest form. The program parses the genome FASTA file and records statsitics about each contig, the length, GC content etc. This type of information is something you would typically provide in a publication or as a way to assess different assemblers/options you may use. \n",
    "\n",
    "The **input** to the program is the genome assembly **FASTA** and the output are various tables and an html/pdf you can export and view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a5245-9a06-4a98-8a00-cd1e0e3db39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "genome=assembled-genome/contigs.fasta\n",
    "\n",
    "# run quast on the genome assembly\n",
    "quast.py $genome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d4b87-b3d8-4b91-acd5-2ee5a7c324aa",
   "metadata": {},
   "source": [
    "## Process 2: **Completeness** assessment using BUSCO\n",
    "\n",
    "- Program: **BUSCO - Benchmarking Universal Single-Copy Orthologs**\n",
    "- Citation: *Seppey, M., Manni, M., & Zdobnov, E. M. (2019). BUSCO: assessing genome assembly and annotation completeness. Gene prediction: methods and protocols, 227-245.*  \n",
    "- Manual: https://busco.ezlab.org/\n",
    "\n",
    "BUSCO is a program utilized to assess the completeness of a genome assembly in terms of the number of found and universal genes. This program makes use of the OrthoDB set of single-copy orthologous that are found in at least 90% of all the organisms in question. There are different data sets for various taxonomic groups (Eukaryotes, Metazoa, Bacteria, Gammaproteobacteria, etc. etc.). The idea is that a newly sequenced genome *should* contain most of these highly conserved genes. If your genome doesn't contain a large portion of these single-copy orthologs it may indicate that your genome is not complete.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/busco_sampling.png\" width=\"40%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "The input to the program is your genome assembly (contigs) as well as a selection of which database to use. The output is a directory with a short summary of the results, a full table with coordinates for each orthologous gene is located in your assembly, and a directory with the nucleotide and amino acid sequences of all the identified sequences.\n",
    "\n",
    "We will focus on the main summary output as a way to provide a simple QC assessment of our assembly, the outputs provided by BUSCO however have many uses, such as phylogenomics and gene prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ac192-7110-4b92-81f6-1ef79a029784",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# View available sets\n",
    "busco --list-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfe6ed-5542-456f-9abf-9c081ef5eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# run BUSCO\n",
    "busco -i contigs.fasta -m genome -o output-busco -l bacteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2dd37b-99b4-4e8e-b08c-43c99e9b809e",
   "metadata": {},
   "source": [
    "### Examine the BUSCO output.\n",
    "The first file we will look at is the 'short_summary_busco_output.txt'. This is a file which summarizes the main findings, how many of the expected genes did we find? This summary breaks the report into four main categories: **complete single-copy genes, complete duplicated genes, fragmented genes, and missing genes**. \n",
    "\n",
    "We are hopeful that the majority of our genes will be found as 'complete single-copy'. Duplicated genes could indicate that that particular gene underwent a gene duplication event or that we had a miss assembly and essentially have two copies of a region of our genome. Fragmented genes are an artifact of the fact that our genome did not assemble perfectly. Some of our genome is fragmented into multiple contigs, and with that some of our genes are going to be fragmented as well. This is why it is important to inspect the N50 of the genome with QUAST. We want the majority of our contigs to be at least as big as a gene, if it's not than we will have many fragmented genes as a result.\n",
    "\n",
    "Next we will view the 'full_table_busco_output.tsv' file. This is a file which shows the coordinates for all the associated single copy genes in our genome. It also provides information about the status of that ortholog (missing, complete, fragmented). This tsv file can be exported and viewed in excel.\n",
    "\n",
    "The final files we will examine are in a directory called 'single_copy_busco_sequences/'. This houses all the amino acid and protein sequences. This is a rich source for comparative genomics and other sorts of analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b999c3-d1c8-409b-a590-6a533947d91f",
   "metadata": {},
   "source": [
    "## Process 3: **Coverage** assessment using BWA\n",
    "\n",
    "- BWA manual: http://bio-bwa.sourceforge.net/bwa.shtml\n",
    "- samtools manual: http://www.htslib.org/doc/samtools-1.2.html\n",
    "\n",
    "Read Mapping refers to the process of aligning short reads to a reference sequence. This reference can be a complete genome, a transcriptome, or in our case de novo assembly. Read mapping is fundamental to many commonly used pipelines like differential expression or SNP analysis. We will be using it to calculate the average coverage of each of our contigs and to calculate the overall coverage of our genome (a requirement for genbank submission).The main output of read mapping is a Sequence Alignment Map format (SAM). The file provides information about where our sequencing reads match to our assembly and information about how it maps. There are hundreds of programs that use SAM files as a primary input. A BAM file is the binary version of a SAM, and can be converted very easily using samtools.\n",
    "\n",
    "SAM format specifications: https://samtools.github.io/hts-specs/SAMv1.pdf\n",
    "\n",
    "Many programs perform read mapping. The recommended program depends on what you are trying to do. My favorite is 'BWA mem' which balances performance and accuracy well. The input to the program is a referece assembly and reads to map (forward and reverse). The output is a SAM file. By default BWA writes the SAM file to standard output, I therefore save it directly to a file. There are lots of options, please see the manual to understand what I am using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7007c-b87e-4334-8de6-738c4182c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# starting genome from submodule 1\n",
    "genome=assembled-genome/contigs.fasta\n",
    "\n",
    "# raw reads from submodule 1\n",
    "forward=raw-reads/SRR10056829_1.fastq.gz\n",
    "reverse=raw-reads/SRR10056829_2.fastq.gz\n",
    "\n",
    "# Step 1: Index your reference genome. This is a requirement before read mapping.\n",
    "bwa index $genome\n",
    "# Step 2: Map the reads and construct a SAM file.\n",
    "bwa mem -t 24 $genome $forward $reverse > raw_mapped.sam\n",
    "# view the file with less, note that to see the data you have to scroll down past all the headers (@SQ).\n",
    "less -S raw_mapped.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757d9d4-53e5-43a9-b76c-a91b2b19e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Remove sequencing reads that did not match to the assembly and convert the SAM to a BAM.\n",
    "samtools view -@ 24 -Sb  raw_mapped.sam  | samtools sort -@ 24 - sorted_mapped\n",
    "\n",
    "# Examine how many reads mapped with samtools\n",
    "samtools flagstat sorted_mapped.bam\n",
    "# Calculate per base coverage with bedtools\n",
    "\n",
    "# index the new bam file\n",
    "samtools index sorted_mapped.bam\n",
    "\n",
    "bedtools genomecov -ibam sorted_mapped.bam > coverage.out\n",
    "# Calculate per contig coverage with gen_input_table.py\n",
    "gen_input_table.py  --isbedfiles $fasta coverage.out >  coverage_table.tsv\n",
    "# This outputs a simple file with two columns, the contig header and the average coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd84a5-3d7a-4f1b-b824-e0a1332ed623",
   "metadata": {},
   "source": [
    "## Process 4 - Taxonomic assignment using BLAST and blobtools\n",
    "\n",
    "\n",
    "manual: https://www.ncbi.nlm.nih.gov/books/NBK279690/\n",
    "\n",
    "Using the command line BLAST works essentially the same as NCBI BLAST except we have more control. We can specify more options like output formats and also use our own local databases. It is also a lot more useful for pipelines and workflows since it can be automated, you don't need to open a web page and fill out any forms.\n",
    "\n",
    "As a quick example for how BLAST works we will use the same 16S_sequence and BLAST it against our genome assembly. Before we begin we will make a database out of our contig assembly. This is done to construct a set of files that BLAST can use to speed up its sequence lookup. In the end it means we have to wait less time for our results.\n",
    "\n",
    "#### Make a BLAST db from your contig files\n",
    "\n",
    "The only required input is a FASTA file (our contigs), the database type (nucl or prot), and an output name for the new database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01f350-d0be-489d-b1b2-0b4d179a351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "genome=assembled-genome/contigs.fasta\n",
    "\n",
    "makeblastdb -in contigs.fasta -dbtype nucl -out contigs_db "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98aa349-8760-430f-b6a2-6cce11e49be1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "696979b8-dd31-42a0-ac7f-92513b6c909c",
   "metadata": {},
   "source": [
    "### BLAST genome assembly against the nt database\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/nucleutide-blast-cover.png\" width=\"30%\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "We store a local copy of the complete nucleotide database on our server. We will be using this to provide a rough taxonomy to every sequence in our assembly and to ultimately identify non-target contaminates (like human and other bacteria) and to confirm our species identification from the 16S BLAST. Later we will be using the output file as in input to blobtools and to visualize this information. blobtools requires a specifically formatted BLAST file, I therefore provide a script that will run the BLAST to the programs specification. We will simply provide the script with our contigs file and it will complete the task. This is a simple script that is not much different than the example we ran above. It will automatically format a meaningfull output name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77df83-5089-4a97-bdb1-0117e686ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "genome=assembled-genome/contigs.fasta\n",
    "database=data/ncbi_nt/nt\n",
    "outname=blast_nt\n",
    "\n",
    "blastn \\\n",
    "    -task megablast \\\n",
    "    -query $contig \\\n",
    "    -db $database\\\n",
    "    -outfmt '6 qseqid staxids bitscore std sscinames sskingdoms stitle' \\\n",
    "    -culling_limit 5 \\\n",
    "    -max_target_seqs 10 \\\n",
    "    -num_threads 24 \\\n",
    "    -evalue 1e-5 \\\n",
    "     -out $outname.vs.nt.cul5.maxt10.1e5.megablast.out &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b74686-e191-49df-a773-4df1fe8e5da2",
   "metadata": {},
   "source": [
    "## Combine datasets into a blobtools database\n",
    "\n",
    "Program: BlobTools  \n",
    "Citation: *Laetsch, D. R., & Blaxter, M. L. (2017). BlobTools: Interrogation of genome assemblies. F1000Research, 6, 1287*  \n",
    "Manual: https://blobtools.readme.io/docs  \n",
    "\n",
    "Blobtools is a tool to visualize our genome assembly. It is also useful for filtering read and assembly data sets. There are three main inputs to the program: 1.) Contig file (the one we used for BLAST and BWA), 2.) a 'hits' file generated from BLAST, 3.) A SAM or BAM file. The main output of the program are blobplots which plot the GC, coverage, taxonomy, and contigs lengths on a single graph.  \n",
    "\n",
    "The first step (blobtools create) in this short pipeline takes all of our input files and creates a lookup table that is used for plotting and constructing tables. This step does the brunt of the working, parsing the BLAST file to assign taxonomy to each of our sequences, and parsing the SAM file to calculate coverage information.  \n",
    "\n",
    "After that is complete we will use 'blobtools view' to output all the data into a human readable table. Finally we will use 'blobtools plot' to construct the blobplot visuals.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5cfb06-247c-41a9-9b97-7ca4f7c1d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create lookup table\n",
    "blobtools create --help\n",
    "blobtools create -i contigs.fasta -b sorted_mapped.bam -t contigs.fasta.vs.nt.cul5.1e5.megablast.out -o blob_out\n",
    "\n",
    "# Create output table\n",
    "blobtools view --help\n",
    "blobtools view -i blob_out.blobDB.json -r all -o blob_taxonomy\n",
    "\n",
    "# view the table, I remove headers with grep -v and view with tabview\n",
    "grep -v '##' blob_taxonomy.blob_out.blobDB.table.txt\n",
    "\n",
    "# Plot the data\n",
    "blobtools plot --help\n",
    "blobtools plot -i blob_out.blobDB.json -r genus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd578fc1-6777-4d18-af07-9763c8b40627",
   "metadata": {},
   "source": [
    "## Filter non-target sequences from *de novo* assembly\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/example_blobplot.png\" width=\"50%\"/>\n",
    "</p>\n",
    "\n",
    "The x-axis on these plots is GC content, the y-axis is the coverage (log transformed). The size of the 'blobs' are the length of the contigs. Colors represent taxonomic assignment (the -r option lets you choose which rank to view). The concept of these plots and ultimately for assembly filtering is that each organism has a unique GC content. For example Streptomyces has an average GC content of about 0.72 while other bacteria can go as low as 0.2. In addition, contamination is most likely has much lower coverage compared to the rest of your assembly. Combine that with the taxonomic assignments and you have multiple lines of evidence to identify your non-target contigs. In the plot above you can fairly easily see what contigs we plan to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d2f08-d2b1-4dc3-8649-8eb1ac77765f",
   "metadata": {},
   "source": [
    "## Genome annotation using PROKKA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ec592-0435-4037-b2a1-5a262d89d58b",
   "metadata": {},
   "source": [
    "## Visualize Dataset\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/example_genome.png\" width=\"40%\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e48c8e-1fe7-4821-9a31-8fd5a7878624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
